{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy retrained model to DeepLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(from AWS lab deeplens-hotdog-or-not-hotdog\n",
    "https://github.com/aws-samples/reinvent-2017-deeplens-workshop)\n",
    "\n",
    "## Tips:\n",
    "\n",
    "1. To connect to DeepLens, use SSH over WiFi, need to connect USB Keyboard/Mouse and Micro HDMI to HDMI, enable it as per: https://forums.aws.amazon.com/thread.jspa?threadID=268557. Can then connect via SSH shell (e.g. Windows -> Start - Cmd - ssh aws_cam@<IP address from Devices menu in DeepLens>\n",
    "    \n",
    "2. Need to use model optimizer, to create .xml file for an optimized model from the .json/.params files, in the Greengrass Lambda function that gets deployed to the IoT core on the DeepLens. Should be able to have it in the Lambda function, but I had problems with permissions, and module incompativbility (I also like seeing it run and give module warnings, e.g. wrong numpy / mxnet version). Note that the DeepLens is a Python 2.7 device, so use pip2 and python2 commands, with sudo. I ran the mo (model optimizer) locally on the Deeplens:\n",
    "\n",
    "aws_cam@Deepcam:~$ sudo python2\n",
    "\n",
    "[sudo] password for aws_cam:\n",
    "\n",
    "Python 2.7.12 (default, Dec  4 2017, 14:50:18)\n",
    "\n",
    "[GCC 5.4.0 20160609] on linux2\n",
    "\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    "\n",
    "    import awscam, mo\n",
    "\n",
    "    model_path = mo.optimize('deeplens-model', 224, 224)\n",
    "    ...\n",
    "\n",
    "[ SUCCESS ] Generated IR model.\n",
    "\n",
    "[ SUCCESS ] XML file: /opt/awscam/artifacts/deeplens-model.xml\n",
    "\n",
    "[ SUCCESS ] BIN file: /opt/awscam/artifacts/deeplens-model.bin\n",
    "\n",
    "I then refered to this model_path in the Lambda function:\n",
    "\n",
    "def greengrass_infinite_infer_run():\n",
    "\n",
    "    try:\n",
    "    \n",
    "        artifact_file = \"/opt/awscam/artifacts/deeplens-model.xml\"\n",
    "        \n",
    "       ...\n",
    "       \n",
    "       model = awscam.Model(artifact_file, mcfg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model exported in previous step, creating <model-name>-0000.params and <model-name>-symbol.json\n",
    "modelname = \"helmet-detection-model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's push this serialized model to S3, where we can then optimize it for our DeepLense device and then push it down onto our device for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::211266271983:role/AmazonSageMaker-ExecutionRole-20180814T130765\n",
      "<_io.BufferedReader name='helmet-detection-model-symbol.json'>\n",
      "<_io.BufferedReader name='helmet-detection-model-0000.params'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='deeplens-sagemaker-stevehunter', key='test/helmet-detection-model-0000.params')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "assumed_role = boto3.client('sts').get_caller_identity()['Arn']\n",
    "s3_access_role = re.sub(r'^(.+)sts::(\\d+):assumed-role/(.+?)/.*$', r'\\1iam::\\2:role/\\3', assumed_role)\n",
    "print(s3_access_role)\n",
    "s3 = boto3.resource('s3')\n",
    "bucket= 'deeplens-sagemaker-stevehunter' \n",
    "\n",
    "json = open(modelname+'-symbol.json', 'rb')\n",
    "print(json)\n",
    "params = open(modelname+'-0000.params', 'rb')\n",
    "print(params)\n",
    "\n",
    "s3.Bucket(bucket).put_object(Key='test/'+modelname+'-symbol.json', Body=json)\n",
    "\n",
    "s3.Bucket(bucket).put_object(Key='test/'+modelname+'-0000.params', Body=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'awscam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-65f168ae4deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mawscam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'awscam'"
     ]
    }
   ],
   "source": [
    "import awscam\n",
    "import mo\n",
    "error, model_path = mo.optimize(modelname,224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a lambda function\n",
    "\n",
    "1. Navigate to Lambda console: https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions\n",
    "2. Make sure you are on US East-1- N.Virginia region\n",
    "3. Click on Create function\n",
    "4. Click Author from scratch\n",
    "5. Name it deeplens-helmet-detection-full-name\n",
    "6. Choose an existing role\n",
    "7. Choose the existing deeplens_lambda role\n",
    "8. Click Create function\n",
    "\n",
    "## Configure your lambda function\n",
    "\n",
    "1. In the Runtime, change it to python 2.7\n",
    "2. In the handler box, change it to greengrassHelloWorld.function_handler\n",
    "3. In the code entry type, choose Upload a file from my github, copy paste this S3 link: https://github.com/Steve--Hunter/DeepLens-Safety-Helmet/deeplens-helmet-detection-lambda-function-steve-hunter.zip\n",
    "4. Click Save\n",
    "5. Make sure you verify the code you copied exists in the function\n",
    "\n",
    "## Publish your function\n",
    "1. In Actions tab, click publish and provide your name_sagemaker as the description\n",
    "\n",
    "## Create a Project\n",
    "\n",
    "1. Navigate to Projects in the AWS DeepLens console\n",
    "\n",
    "2. Click on Create a new project\n",
    "\n",
    "3. Click on Create a new blank project template\n",
    "\n",
    "4. Give the project a name: safety-helmet-detection\n",
    "\n",
    "5. Click on add model and choose the safetyhelmetdetection\n",
    "\n",
    "6. Click on Add function and choose the deeplens-helmet-detection-steve-hunter-full-name function\n",
    "\n",
    "7. Create project\n",
    "\n",
    "\n",
    "## Deploy project to AWS DeepLens\n",
    "\n",
    "1. Choose the project you just created\n",
    "\n",
    "2. Click deploy to device\n",
    "\n",
    "3. Choose your device\n",
    "\n",
    "4. Review and hit deploy\n",
    "\n",
    "## Use the streaming video feed to test out DeepLens\n",
    "\n",
    "1. From the DeepLens console, https://console.aws.amazon.com/deeplens, choose Devices - View output\n",
    "2. Follow the instructions for setting up your browser (note the streaming certificate was created when the DeepLens was first configured, so use that one if you saved it)\n",
    "3. Select View stream (usually https://192.168.2.17:4000/ for Chrome browsers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
